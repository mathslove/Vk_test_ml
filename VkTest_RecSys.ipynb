{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "521d7205",
   "metadata": {},
   "source": [
    "# Тестовое задание Стажёр в команду CoreML\n",
    "### Маслов Михаил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf86956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76922fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = r'/home/mika/JupyterNotebooks/Vk_test_ml/data/'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# использую для всех случайных процессов чтобы можно было воспроизвести результаты\n",
    "RNG_SEED = 42\n",
    "\n",
    "# для встроенного распараллеливания библиотеки, не уверен что работает\n",
    "os.environ['MKL_THREADING_LAYER'] = 'tbb'\n",
    "os.environ['LK_NUM_PROCS'] = '8,4'\n",
    "os.environ['NUMBA_NUM_THREADS'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b80a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cfa67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape:\t (20000263, 4)\n",
      "min rating:\t 0.5\n",
      "max rating:\t 5.0\n",
      "uniq users count: 138493\n",
      "uniq movies count: 26744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('rating shape:\\t', rating.shape)\n",
    "print('min rating:\\t',rating['rating'].min())\n",
    "print('max rating:\\t',rating['rating'].max())\n",
    "print('uniq users count:', rating['userId'].unique().size)\n",
    "print('uniq movies count:', rating['movieId'].unique().size)\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca24b09",
   "metadata": {},
   "source": [
    "Также стоит отметить, что распределение количества информации известной о пользователях - неравномерное, <br>оно похоже на распределние <a href=\"https://en.wikipedia.org/wiki/Power_law\">степенного закона</a>.<br>\n",
    "Чтобы не загромождать ноутбук графиками, я хотел бы сослаться на неплохую <a href='https://www.kaggle.com/code/saadmuhammad17/data-analysis-of-movielens-25m-dataset'>визуализацию</a> датасета с kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5dd86",
   "metadata": {},
   "source": [
    "## Eval metrics: RMSE & NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdac783",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20\">\n",
    "Обычно для измерения точности рекомнедации используют <i>RMSE</i>, как например в <i>Netflix Prize</i>.<br> \n",
    "Однако достижение хороших показателей с точки зрения <i>RMSE</i> не всегда гарантирует хорошие показатели рекомендательной системы.<br> \n",
    "Также можно добавить, что рейтинг это порядковые данные, то есть 5-3 != 3-1, \n",
    "а \"<i>чистый</i>\" <i>RMSE</i> не учитывет не линейность рейтингов<br><br>\n",
    "Поэтому для измерения качества рекомендательной системы мы также будем использовать метрику <i>NDCG</i>, <br>которая позволит нам оценить соответсвие \"<i>идеальной</i>\" рекомендации.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67783e4c",
   "metadata": {},
   "source": [
    "## Split train validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c1674",
   "metadata": {},
   "source": [
    "переписать мб"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b77a2",
   "metadata": {},
   "source": [
    "Так как наша задача это предсказываение рейтинга фильмов для пользователей, то мы разобьём датасет для каждого пользователя. <br> Также при разбиение мы учтём время, хоть и не все модели его использует, но логично предположить, <br>что время это полезный признак имеющий смысл. <br>\n",
    "Я взял 5 разбиений для кросс валидации, потому что это наиболее популярный варинат и увеличение или умененьшение этого числа не должно дать существенных изменений.<br>\n",
    "Также я взял 5 последних фильмов у каждого пользователя для валидации, так как минимальное колчиество оценок у пользователя 20 и, как мне кажется, при оценки ранжироврованого списка фильмов оценка бует объективнее, если мы будем угадывать для всех одинаковое число фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca190f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lenskit.crossfold as xf\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "rating = rating.rename(columns={'userId': 'user', 'movieId': 'item'})\n",
    "for i, tp in enumerate(xf.partition_users(rating, N_SPLITS, xf.LastN(5), rng_spec=RNG_SEED)):\n",
    "    tp.train.to_csv('20m.train-%d.csv' % (i,))\n",
    "    tp.test.to_csv('20m.test-%d.csv' % (i,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71364374",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8dcc7",
   "metadata": {},
   "source": [
    "### Метод LFM (SVD-like <a href=\"https://sifter.org/~simon/journal/20061211.html\">FunkSVD</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ce54f",
   "metadata": {},
   "source": [
    "Алгоритм:\n",
    "<p>\n",
    "Данный метод использует векторное представление пользователя и объекта,<br>\n",
    "а также средний рейтинг пользователя и объекта<br>\n",
    "С помощью градиентного спуска мы находим векторы для каждого пользователя и объекта.<br>\n",
    "Важной частью этого алгоритма является L2-регуляризация, она предотварщает модель от переобучения, что является проблемой SVD++. Можно отметить, что L1-регуляризация не даёт качественого прироста в точности\n",
    "</p>\n",
    "<p>\n",
    "    \n",
    "Гиперпараметрами алгоритма являются:\n",
    "- количество эпох и/или эпсилон изменения ошибки\n",
    "- количество признаков для предстваления пользователя и объекта\n",
    "\n",
    "</p>\n",
    "<img src='imgs/svd.png'alt=\"без регуляризации\">\n",
    "<i style=\"float:right;\">без регуляризации</i>\n",
    "<img src='imgs/funksvd.png'>\n",
    "<i style=\"float:right;\">с регуляризацией</i>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d5cfc",
   "metadata": {},
   "source": [
    "Далее прочитав статью <a href=\"https://sifter.org/~simon/journal/20061211.html\">Simon Funk</a> и проанализировав <a href=\"https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data\">датасет</a> с <i>Netflix Prize</i>, я решил что наши данные очень схожи и <br> поэтому можно взять гиперпараметры из блога призёра этого исторического конкурса.<br><br>\n",
    "А именно:\n",
    "- количество эпох 120\n",
    "- количество признаков 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98481feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55578a3bfae543e0b6e6e61b0b1fd58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BLAS using multiple threads - can cause oversubscription\n",
      "found 1 potential runtime problems - see https://boi.st/lkpy-perf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 114 ms, total: 265 ms\n",
      "Wall time: 19min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lenskit.algorithms.funksvd import FunkSVD\n",
    "from lenskit.metrics.predict import rmse, global_metric\n",
    "from lenskit.topn import ndcg\n",
    "from joblib import Parallel, delayed\n",
    "import psutil\n",
    "\n",
    "results = []\n",
    "\n",
    "# Можно снизить N_SPLITS c 5 \n",
    "N_SPLITS = 1\n",
    "n_features = 40\n",
    "iterations = 120\n",
    "\n",
    "def train_test_eval_svd(i):\n",
    "    cf_train = pd.read_csv('20m.train-%d.csv' % (i,))\n",
    "    cf_test =  pd.read_csv('20m.test-%d.csv' % (i,))\n",
    "    \n",
    "    cf_model_svd = FunkSVD(features=n_features, iterations=iterations, range=(0.5,5))\n",
    "    cf_model_svd.fit(cf_train)\n",
    "    \n",
    "    # Предсказываем\n",
    "    cf_pred = cf_model_svd.predict(cf_test)\n",
    "    cf_test['prediction'] = cf_pred\n",
    "\n",
    "    # Оцениваем\n",
    "    cf_model_ndcg = ndcg(cf_test.rename(columns={'rating': 'original_rating','prediction': 'rating'}), cf_test)\n",
    "    cf_model_rmse = global_metric(cf_test, metric=rmse)\n",
    "\n",
    "    result = {\n",
    "        'n_features': n_features,\n",
    "        'n_epochs': iterations,\n",
    "        'rmse': cf_model_rmse,\n",
    "        'ndcg': cf_model_ndcg,\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# работа с процессами для библиотеки\n",
    "current_process = psutil.Process()\n",
    "subproc_before = set([p.pid for p in current_process.children(recursive=True)])\n",
    "\n",
    "# на больше n_jobs ОЗУ не хватает\n",
    "results = Parallel(n_jobs=3, backend='multiprocessing')(\n",
    "    delayed(train_test_eval_svd)(i) for i in tqdm(range(N_SPLITS)))\n",
    "\n",
    "# особенность библиотеки чтобы завершить выполнение\n",
    "subproc_after = set([p.pid for p in psutil.Process().children(recursive=True)])\n",
    "for subproc in subproc_after - subproc_before:\n",
    "    psutil.Process(subproc).terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc55b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg RMSE: 0.8577087331709268\n",
      "Avg NDCG: 0.9694998266280797\n"
     ]
    }
   ],
   "source": [
    "avg_rmse = sum([res['rmse'] for res in results])/len(results)\n",
    "avg_ndcg = sum([res['ndcg'] for res in results])/len(results)\n",
    "print('Avg RMSE:', avg_rmse)\n",
    "print('Avg NDCG:', avg_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473960c5",
   "metadata": {},
   "source": [
    "## Collaborative + content filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60134f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'/home/mika/JupyterNotebooks/Vk_test_ml/data/'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# использую для всех случайных процессов чтобы можно было воспроизвести результаты\n",
    "RNG_SEED = 42\n",
    "\n",
    "genome_scores = pd.read_csv('genome_scores.csv')\n",
    "genome_tags = pd.read_csv('genome_tags.csv')\n",
    "link = pd.read_csv('link.csv')\n",
    "movie = pd.read_csv('movie.csv')\n",
    "rating = pd.read_csv('rating.csv')\n",
    "tag = pd.read_csv('tag.csv')\n",
    "\n",
    "n_features = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d62e717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genome_scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.09675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  tagId  relevance\n",
       "0        1      1    0.02500\n",
       "1        1      2    0.02500\n",
       "2        1      3    0.05775\n",
       "3        1      4    0.09675\n",
       "4        1      5    0.14675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'genome_tags'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagId           tag\n",
       "0      1           007\n",
       "1      2  007 (series)\n",
       "2      3  18th century\n",
       "3      4         1920s\n",
       "4      5         1930s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'movie'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'rating'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tag'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4141</td>\n",
       "      <td>Mark Waters</td>\n",
       "      <td>2009-04-24 18:19:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>2013-05-10 01:41:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>353</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>2013-05-10 01:41:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>521</td>\n",
       "      <td>noir thriller</td>\n",
       "      <td>2013-05-10 01:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>592</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>2013-05-10 01:41:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId            tag            timestamp\n",
       "0      18     4141    Mark Waters  2009-04-24 18:19:40\n",
       "1      65      208      dark hero  2013-05-10 01:41:18\n",
       "2      65      353      dark hero  2013-05-10 01:41:19\n",
       "3      65      521  noir thriller  2013-05-10 01:39:43\n",
       "4      65      592      dark hero  2013-05-10 01:41:18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('genome_scores', genome_scores.head())\n",
    "display('genome_tags', genome_tags.head())\n",
    "display('movie', movie.head())\n",
    "display('rating', rating.head())\n",
    "display('tag', tag.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e8afe",
   "metadata": {},
   "source": [
    "### Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6d319",
   "metadata": {},
   "source": [
    "Категориальный признак - это признак, который не выражает непрерывную величину, а принимает одно из фиксированных значений.<br>\n",
    "\n",
    "Этот признак можно первратить в многомерный вектор, чтобы его можно было использовать в модели.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e920c",
   "metadata": {},
   "source": [
    "### Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333e44e",
   "metadata": {},
   "source": [
    "Ещё можно нормализовать время(timestamp), тк оно слишком велико и лежит в определённых рамках. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639055",
   "metadata": {},
   "source": [
    "### Текстовые данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad0e22d",
   "metadata": {},
   "source": [
    "Также можно добавить текстовые признаки в нашу модель. Обычно такие вещи, как описания продуктов, представляют собой текст в свободной форме, и мы можем надеяться, что наша модель сможет научиться использовать содержащуюся в них информацию для выработки лучших рекомендаций, особенно в случае холодного запуска или длинного хвоста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e86e7",
   "metadata": {},
   "source": [
    "<!-- ### TODO: Убрать мешуру и всё в одну модель, поменять tsdf где можно(медленные) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9565631",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 14:57:26.518563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-04 14:57:26.518966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.519340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.519413: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.519476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.519538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.519599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.519964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.520029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-04-04 14:57:26.520040: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-04 14:57:26.522077: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "rating['timestamp'] = rating['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').toordinal())\n",
    "rating['userId'] = rating['userId'].to_numpy().astype(str)\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(rating.merge(movie)))\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(movie))\n",
    "\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"title\"],\n",
    "    \"user_id\": x[\"userId\"],\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83044099",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")\n",
    "\n",
    "unique_movie_titles = movie.title.unique()\n",
    "unique_user_ids = rating.userId.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3415e3f",
   "metadata": {},
   "source": [
    "### Собираем итоговую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21c54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "    ])\n",
    "    self.timestamp_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "        tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "    ])\n",
    "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "        axis=None\n",
    "    )\n",
    "\n",
    "    self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71143034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "          vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(movies)\n",
    "\n",
    "  def call(self, titles):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(titles),\n",
    "        self.title_text_embedding(titles),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b670e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, layer_sizes):\n",
    "    super().__init__()\n",
    "\n",
    "    self.embedding_model = MovieModel()\n",
    "\n",
    "    self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "    for layer_size in layer_sizes[:-1]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    for layer_size in layer_sizes[-1:]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    feature_embedding = self.embedding_model(inputs)\n",
    "    return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e8a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, layer_sizes):\n",
    "    super().__init__()\n",
    "\n",
    "    # We first use the user model for generating embeddings.\n",
    "    self.embedding_model = UserModel()\n",
    "\n",
    "    # Then construct the layers.\n",
    "    self.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "    # Use the ReLU activation for all but the last layer.\n",
    "    for layer_size in layer_sizes[:-1]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "    # No activation for the last layer.\n",
    "    for layer_size in layer_sizes[-1:]:\n",
    "      self.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "  def call(self, inputs):\n",
    "    feature_embedding = self.embedding_model(inputs)\n",
    "    return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddadbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, layer_sizes):\n",
    "    super().__init__()\n",
    "    self.query_model = QueryModel(layer_sizes)\n",
    "    self.candidate_model = CandidateModel(layer_sizes)\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    query_embeddings = self.query_model({\n",
    "        \"user_id\": features[\"user_id\"],\n",
    "        \"timestamp\": features[\"timestamp\"],\n",
    "    })\n",
    "    movie_embeddings = self.candidate_model(features[\"movie_title\"])\n",
    "\n",
    "    return self.task(\n",
    "        query_embeddings, movie_embeddings, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e29052",
   "metadata": {},
   "source": [
    "Обучение модели очень дорогое, поэтому проверим всего на одном train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6cfe73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 25s, sys: 23.8 s, total: 7min 48s\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_SPLITS = 1\n",
    "num_epochs = 3\n",
    "test_size = 0.2\n",
    "\n",
    "tf.random.set_seed(RNG_SEED)\n",
    "\n",
    "\n",
    "# Читаем split с диска\n",
    "nn_train = pd.read_csv('20m.train-%d.csv' % (0,))\n",
    "nn_test =  pd.read_csv('20m.test-%d.csv' % (0,))\n",
    "nn_train_size = len(nn_train.index)\n",
    "\n",
    "# Форматируем данные под модель\n",
    "nn_train['timestamp'] = nn_train['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').toordinal())\n",
    "nn_train['user'] = nn_train['user'].to_numpy().astype(str)\n",
    "nn_train = nn_train.rename(columns={'user': 'user_id', 'item': 'movieId'})\n",
    "nn_train = nn_train.merge(movie)\n",
    "nn_train = nn_train.rename(columns={'title': 'movie_title', 'movieId': 'movie_id'})\n",
    "\n",
    "nn_test['timestamp'] = nn_test['timestamp'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').toordinal())\n",
    "nn_test['user'] = nn_test['user'].to_numpy().astype(str)\n",
    "nn_test = nn_test.rename(columns={'user': 'user_id', 'item': 'movieId'})\n",
    "nn_test = nn_test.merge(movie)\n",
    "nn_test = nn_test.rename(columns={'title': 'movie_title','movieId': 'movie_id'})\n",
    "nn_test = tf.data.Dataset.from_tensor_slices(dict(nn_test))\n",
    "\n",
    "# Компилируем модель и разбиваем train \n",
    "model = MovielensModel([32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "shuffled = ratings.shuffle(nn_train_size, seed=RNG_SEED, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(nn_train_size*(1-test_size)))\n",
    "test = shuffled.skip(int(nn_train_size*(1-test_size))).take(int(nn_train_size*test_size))\n",
    "\n",
    "cached_train = train.shuffle(nn_train_size).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e14e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 15:10:12.741686: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 2281268 of 19861768\n",
      "2022-04-04 15:10:22.741684: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 4430162 of 19861768\n",
      "2022-04-04 15:10:32.741685: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 6614077 of 19861768\n",
      "2022-04-04 15:10:42.741691: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 8704374 of 19861768\n",
      "2022-04-04 15:10:52.742367: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 10784691 of 19861768\n",
      "2022-04-04 15:11:02.741696: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 12744427 of 19861768\n",
      "2022-04-04 15:11:12.741682: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 14614227 of 19861768\n",
      "2022-04-04 15:11:22.741685: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 16649771 of 19861768\n",
      "2022-04-04 15:11:32.819701: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 18628591 of 19861768\n",
      "2022-04-04 15:11:42.234594: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2022-04-04 15:11:42.236213: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1 of 19861768\n",
      "2022-04-04 15:11:42.237052: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 2 of 19861768\n",
      "2022-04-04 15:11:42.237068: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 3 of 19861768\n",
      "2022-04-04 15:11:42.237076: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 4 of 19861768\n",
      "2022-04-04 15:11:42.237083: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 5 of 19861768\n",
      "2022-04-04 15:11:42.237089: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 6 of 19861768\n",
      "2022-04-04 15:11:42.237096: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 7 of 19861768\n",
      "2022-04-04 15:11:42.237104: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 8 of 19861768\n",
      "2022-04-04 15:11:42.237111: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 9 of 19861768\n",
      "2022-04-04 15:11:42.641062: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 29070 of 19861768\n",
      "2022-04-04 15:11:52.641060: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 5240340 of 19861768\n",
      "2022-04-04 15:12:02.641060: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 11080093 of 19861768\n",
      "2022-04-04 15:12:12.251670: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Обучение\n",
    "nn_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=10,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0)\n",
    "\n",
    "print(1)\n",
    "# Предсказываем\n",
    "pred = model.predict(nn_test.cache(), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b88d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lenskit.metrics.predict import rmse, global_metric\n",
    "from lenskit.topn import ndcg\n",
    "\n",
    "num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, nn_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e23027",
   "metadata": {},
   "source": [
    "Итог моей контетной колобаративной модели в том что она не смогла посчитаться, из-за нехватки оперативной памяти и всех overhead, что я накрутил.<br>\n",
    "Последняя модель явно вышла, сырой, но это только из-за моих технических проблем. Возможно было бы чуть больше времени, я бы сделал по-другому и красивее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4e45a",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3419e",
   "metadata": {},
   "source": [
    "Хоть моя попытка сделать контентную модель провалилась, в техническом плане, всё равно можно сказать, что контентные признаки несут в себе полезную информацию и точность у такой модели должна быть выше, чем у чисто коллоборативной.<br><br>\n",
    "Также в будущем можно улучшить точность обеих моделей в выбранных метриках, если заставить модели оптимизировать именно эти метрики, но целесообразность этого стоит проверить на A/B тестах. Не всегда хорошие значения в метрике, значит что рекомендательная система хорошо работает, онлайн метрики в совокупности с офлайн дают более полной представлнение о качестве работы системы.\n",
    "<br><br>\n",
    "\n",
    "P.S.:<br>\n",
    "Я потратил слишком много времени и сил на кросс валидацию и копание в моделях, чем на выполнение самого задание.<br> Сейчас очевидо, что подбирать и брать большие гиперпараметры это не такая значимая часть исследования.<br> Лучшее несколько теоритических моделей, чем одна кроссвалидированая)<br>\n",
    "Попробую переделать контентную модель, но уже в не рамках зачёта.<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 165.844,
   "position": {
    "height": "206.844px",
    "left": "17px",
    "right": "20px",
    "top": "88px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
