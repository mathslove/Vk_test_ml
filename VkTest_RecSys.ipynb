{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "521d7205",
   "metadata": {},
   "source": [
    "# Тестовое задание Стажёр в команду CoreML\n",
    "### Маслов Михаил\n",
    "#### Linux, 16G RAM (+6G swap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf86956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76922fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = r'/home/mika/JupyterNotebooks/Vk_test_ml/data/'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# использую для всех случайных процессов чтобы можно было воспроизвести результаты\n",
    "RNG_SEED = 42\n",
    "\n",
    "# для встроенного распараллеливания библиотеки, не уверен что работает\n",
    "os.environ['MKL_THREADING_LAYER'] = 'tbb'\n",
    "os.environ['LK_NUM_PROCS'] = '8,4'\n",
    "os.environ['NUMBA_NUM_THREADS'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b80a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv('rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cfa67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape:\t (20000263, 4)\n",
      "min rating:\t 0.5\n",
      "max rating:\t 5.0\n",
      "uniq users count: 138493\n",
      "uniq movies count: 26744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39\n",
       "3       1       47     3.5  2005-04-02 23:32:07\n",
       "4       1       50     3.5  2005-04-02 23:29:40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('rating shape:\\t', rating.shape)\n",
    "print('min rating:\\t',rating['rating'].min())\n",
    "print('max rating:\\t',rating['rating'].max())\n",
    "print('uniq users count:', rating['userId'].unique().size)\n",
    "print('uniq movies count:', rating['movieId'].unique().size)\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca24b09",
   "metadata": {},
   "source": [
    "Также стоит отметить, что распределение количества информации известной о пользователях - неравномерное, <br>оно похоже на распределние <a href=\"https://en.wikipedia.org/wiki/Power_law\">степенного закона</a>.<br>\n",
    "Чтобы не загромождать ноутбук графиками, я хотел бы сослаться на неплохую <a href='https://www.kaggle.com/code/saadmuhammad17/data-analysis-of-movielens-25m-dataset'>визуализацию</a> датасета с kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5dd86",
   "metadata": {},
   "source": [
    "## Eval metrics: RMSE & NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdac783",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 20\">\n",
    "Обычно для измерения точности рекомнедации используют <i>RMSE</i>, как например в <i>Netflix Prize</i>.<br> \n",
    "Однако достижение хороших показателей с точки зрения <i>RMSE</i> не всегда гарантирует хорошие показатели рекомендательной системы.<br> \n",
    "Также можно добавить, что рейтинг это порядковые данные, то есть 5-3 != 3-1, \n",
    "а \"<i>чистый</i>\" <i>RMSE</i> не учитывет не линейность рейтингов<br><br>\n",
    "Поэтому для измерения качества рекомендательной системы мы также будем использовать метрику <i>NDCG</i>, <br>которая позволит нам оценить соответсвие \"<i>идеальной</i>\" рекомендации.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67783e4c",
   "metadata": {},
   "source": [
    "## Split train validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c1674",
   "metadata": {},
   "source": [
    "переписать мб"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b77a2",
   "metadata": {},
   "source": [
    "Так как наша задача это предсказываение рейтинга фильмов для пользователей, то мы разобьём датасет для каждого пользователя. <br> Также при разбиение мы учтём время, хоть и не все модели его использует, но логично предположить, <br>что время это полезный признак имеющий смысл. <br>\n",
    "Я взял 5 разбиений для кросс валидации, потому что это наиболее популярный варинат и увеличение или умененьшение этого числа не должно дать существенных изменений.<br>\n",
    "Также я взял 5 последних фильмов у каждого пользователя для валидации, так как минимальное колчиество оценок у пользователя 20 и, как мне кажется, при оценки ранжироврованого списка фильмов оценка бует объективнее, если мы будем угадывать для всех одинаковое число фильмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca190f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lenskit.crossfold as xf\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "rating = rating.rename(columns={'userId': 'user', 'movieId': 'item'})\n",
    "for i, tp in enumerate(xf.partition_users(rating, N_SPLITS, xf.LastN(5), rng_spec=RNG_SEED)):\n",
    "    tp.train.to_csv('20m.train-%d.csv' % (i,))\n",
    "    tp.test.to_csv('20m.test-%d.csv' % (i,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71364374",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8dcc7",
   "metadata": {},
   "source": [
    "### Метод LFM (SVD-like <a href=\"https://sifter.org/~simon/journal/20061211.html\">FunkSVD</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ce54f",
   "metadata": {},
   "source": [
    "Алгоритм:\n",
    "<p>\n",
    "Данный метод использует векторное представление пользователя и объекта,<br>\n",
    "а также средний рейтинг пользователя и объекта<br>\n",
    "С помощью градиентного спуска мы находим векторы для каждого пользователя и объекта.<br>\n",
    "Важной частью этого алгоритма является L2-регуляризация, она предотварщает модель от переобучения, что является проблемой SVD++. Можно отметить, что L1-регуляризация не даёт качественого прироста в точности\n",
    "</p>\n",
    "<p>\n",
    "    \n",
    "Гиперпараметрами алгоритма являются:\n",
    "- количество эпох и/или эпсилон изменения ошибки\n",
    "- количество признаков для предстваления пользователя и объекта\n",
    "\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<img src='imgs/svd.png'alt=\"без регуляризации\">\n",
    "<i style=\"float:right;\">без регуляризации</i>\n",
    "\n",
    "<img src='imgs/funksvd.png'>\n",
    "<i style=\"float:right;\">с регуляризацией</i>\n",
    "<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d5cfc",
   "metadata": {},
   "source": [
    "Далее прочитав статью <a href=\"https://sifter.org/~simon/journal/20061211.html\">Simon Funk</a> и проанализировав <a href=\"https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data\">датасет</a> с <i>Netflix Prize</i>, я решил что наши данные очень схожи и <br> поэтому можно взять гиперпараметры из блога призёра этого исторического конкурса.<br><br>\n",
    "А именно:\n",
    "- количество эпох 120\n",
    "- количество признаков 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98481feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55578a3bfae543e0b6e6e61b0b1fd58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BLAS using multiple threads - can cause oversubscription\n",
      "found 1 potential runtime problems - see https://boi.st/lkpy-perf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 114 ms, total: 265 ms\n",
      "Wall time: 19min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lenskit.algorithms.funksvd import FunkSVD\n",
    "from lenskit.metrics.predict import rmse, global_metric\n",
    "from lenskit.topn import ndcg\n",
    "from joblib import Parallel, delayed\n",
    "import psutil\n",
    "\n",
    "results = []\n",
    "\n",
    "# Можно снизить N_SPLITS c 5 \n",
    "N_SPLITS = 1\n",
    "n_features = 40\n",
    "iterations = 120\n",
    "\n",
    "def train_test_eval_svd(i):\n",
    "    cf_train = pd.read_csv('20m.train-%d.csv' % (i,))\n",
    "    cf_test =  pd.read_csv('20m.test-%d.csv' % (i,))\n",
    "    \n",
    "    cf_model_svd = FunkSVD(features=n_features, iterations=iterations, range=(0.5,5))\n",
    "    cf_model_svd.fit(cf_train)\n",
    "    \n",
    "    # Предсказываем\n",
    "    cf_pred = cf_model_svd.predict(cf_test)\n",
    "    cf_test['prediction'] = cf_pred\n",
    "\n",
    "    # Оцениваем\n",
    "    cf_model_ndcg = ndcg(cf_test.rename(columns={'rating': 'original_rating','prediction': 'rating'}), cf_test)\n",
    "    cf_model_rmse = global_metric(cf_test, metric=rmse)\n",
    "\n",
    "    result = {\n",
    "        'n_features': n_features,\n",
    "        'n_epochs': iterations,\n",
    "        'rmse': cf_model_rmse,\n",
    "        'ndcg': cf_model_ndcg,\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# работа с процессами для библиотеки\n",
    "current_process = psutil.Process()\n",
    "subproc_before = set([p.pid for p in current_process.children(recursive=True)])\n",
    "\n",
    "# на больше n_jobs ОЗУ не хватает\n",
    "results = Parallel(n_jobs=3, backend='multiprocessing')(\n",
    "    delayed(train_test_eval_svd)(i) for i in tqdm(range(N_SPLITS)))\n",
    "\n",
    "# особенность библиотеки чтобы завершить выполнение\n",
    "subproc_after = set([p.pid for p in psutil.Process().children(recursive=True)])\n",
    "for subproc in subproc_after - subproc_before:\n",
    "    psutil.Process(subproc).terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc55b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg RMSE: 0.8577087331709268\n",
      "Avg NDCG: 0.9694998266280797\n"
     ]
    }
   ],
   "source": [
    "avg_rmse = sum([res['rmse'] for res in results])/len(results)\n",
    "avg_ndcg = sum([res['ndcg'] for res in results])/len(results)\n",
    "print('Avg RMSE:', avg_rmse)\n",
    "print('Avg NDCG:', avg_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473960c5",
   "metadata": {},
   "source": [
    "## Collaborative + content filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e21e06",
   "metadata": {},
   "source": [
    "На этот раз я отказался от использования самописных нейроных сетей и взял библиотеку LightFM, которая позволяет использовать контентые признаки. В качестве контентного признака я выбрал жанры фильмов, по сути это категориальный признак, но в текстовом формате, и у одного объекта может быть несколько категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10ea25",
   "metadata": {},
   "source": [
    "По описанию библиотеки LightFM использует матричную факторизацию для решения задачи рекомендации, но с возможностью использовать не только user-item призанки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974cfc0",
   "metadata": {},
   "source": [
    "### Подбор гиперпарметоров\n",
    "Я уменьшил количество латентных факторов в два раза по сравнению с прошлой моделью в угоду производительности с 40 жо 20, так как надеюсь, что контентый признак компенсирует потери, а также количество обучающих эпох я взял 20 вместо 120 по тем же причинам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9fa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import os\n",
    "from datetime import datetime\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60134f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'/home/mika/JupyterNotebooks/Vk_test_ml/data/'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# использую для всех случайных процессов чтобы можно было воспроизвести результаты\n",
    "RNG_SEED = 42\n",
    "\n",
    "movie = pd.read_csv('movie.csv')\n",
    "rating = pd.read_csv('rating.csv').merge(movie)\n",
    "n_features = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d62e717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rating'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-12-25 15:26:09</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-11-27 08:19:02</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-06-23 20:36:14</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-10-28 13:29:44</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp           title  \\\n",
       "0       1        2     3.5  2005-04-02 23:53:47  Jumanji (1995)   \n",
       "1       5        2     3.0  1996-12-25 15:26:09  Jumanji (1995)   \n",
       "2      13        2     3.0  1996-11-27 08:19:02  Jumanji (1995)   \n",
       "3      29        2     3.0  1996-06-23 20:36:14  Jumanji (1995)   \n",
       "4      34        2     3.0  1996-10-28 13:29:44  Jumanji (1995)   \n",
       "\n",
       "                       genres  \n",
       "0  Adventure|Children|Fantasy  \n",
       "1  Adventure|Children|Fantasy  \n",
       "2  Adventure|Children|Fantasy  \n",
       "3  Adventure|Children|Fantasy  \n",
       "4  Adventure|Children|Fantasy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'movie'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>55844</td>\n",
       "      <td>Itty Bitty Titty Committee (2007)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19057</th>\n",
       "      <td>94813</td>\n",
       "      <td>Chernobyl Diaries (2012)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15619</th>\n",
       "      <td>79525</td>\n",
       "      <td>Human Desire (1954)</td>\n",
       "      <td>Drama|Film-Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16884</th>\n",
       "      <td>85374</td>\n",
       "      <td>Emma (1932)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2319</td>\n",
       "      <td>Reach the Rock (1998)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                              title                genres\n",
       "12219    55844  Itty Bitty Titty Committee (2007)  Comedy|Drama|Romance\n",
       "19057    94813           Chernobyl Diaries (2012)                Horror\n",
       "15619    79525                Human Desire (1954)       Drama|Film-Noir\n",
       "16884    85374                        Emma (1932)  Comedy|Drama|Romance\n",
       "2234      2319              Reach the Rock (1998)          Comedy|Drama"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('rating', rating.head())\n",
    "display('movie', movie.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603b6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "movie_genre = [x.split('|') for x in rating['genres']]\n",
    "all_movie_genre = sorted(list(set(itertools.chain.from_iterable(movie_genre))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eafe6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(no genres listed)',\n",
       " 'Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Children',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Fantasy',\n",
       " 'Film-Noir',\n",
       " 'Horror',\n",
       " 'IMAX',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Sci-Fi',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_movie_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c733e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.fit(rating['userId'], \n",
    "            rating['movieId'], \n",
    "            item_features=all_movie_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771b5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = dataset.build_item_features(\n",
    "    (x, y) for x,y in zip(rating['movieId'], movie_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f22e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions(rating[['userId', 'movieId', 'rating']].values)\n",
    "uid_map, ufeature_map, iid_map, ifeature_map = dataset.mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b239af",
   "metadata": {},
   "source": [
    "У меня не хватает памяти для одноврменного хранения всех данных, поэтому очистим те что уже не нужны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "189a8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rating, dataset\n",
    "%reset_selective -f rating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fa2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('20m.train-0.csv').rename(columns={'user':'userId', 'item': 'movieId'}).merge(movie)\n",
    "train_dataset = Dataset()\n",
    "train_dataset.fit(train['userId'], \n",
    "            train['movieId'], \n",
    "            item_features=all_movie_genre)\n",
    "\n",
    "(train_interactions, t_weights) = train_dataset.build_interactions(train[['userId', 'movieId', 'rating']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f584315",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = LightFM(loss='warp', no_components=n_features, \n",
    "                 learning_rate=0.1, \n",
    "                 item_alpha=1e-6,\n",
    "                 user_alpha=1e-6,\n",
    "                 random_state=np.random.RandomState(RNG_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88d5edf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 38min 5s, sys: 1min 34s, total: 1h 39min 39s\n",
      "Wall time: 8min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f1f79ff3850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hybrid_model.fit(interactions=train_interactions,\n",
    "           item_features=item_features,\n",
    "           epochs=20, num_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf84856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('20m.test-0.csv').rename(columns={'user':'userId', 'item': 'movieId'}).merge(movie)\n",
    "\n",
    "users, items, preds = [], [], []\n",
    "item = list(test.movieId.unique())\n",
    "for user in test.userId.unique():\n",
    "    user = [user] * len(item)\n",
    "    users.extend(user)\n",
    "    items.extend(item)\n",
    "test[\"uid\"] = test.userId.map(uid_map)\n",
    "test[\"iid\"] = test.movieId.map(iid_map)\n",
    "test[\"prediction\"] = test.apply(\n",
    "        lambda x: hybrid_model.predict(\n",
    "            user_ids=np.array([x[\"uid\"]], dtype=np.int32),\n",
    "            item_ids=np.array([x[\"iid\"]], dtype=np.int32),\n",
    "            item_features=item_features,\n",
    "            num_threads=32,\n",
    "        )[0],\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "776f9b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3780868573072507\n",
      "NDCG: 0.9780378327939213\n"
     ]
    }
   ],
   "source": [
    "from lenskit.topn import ndcg\n",
    "from lenskit.metrics.predict import rmse, global_metric\n",
    "\n",
    "hybrid_ndcg = ndcg(test.rename(columns={'rating': 'original_rating','prediction': 'rating', 'movieId':'item', 'userId':'user'}), test)\n",
    "hybrid_rmse = global_metric(test, metric=rmse)\n",
    "\n",
    "print('RMSE:', hybrid_rmse)\n",
    "print('NDCG:', hybrid_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4e45a",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3419e",
   "metadata": {},
   "source": [
    "CF модель показала неплохие результаты, имея малое число признаков, но намного больше времени для обучения(~6 раз). Гибридная модель имела меньшее время обучения и параметров описывающих признаки, но показала результат даже лучше по метрике NDCG, но проиграла значительно в точном предсказание рейтнига.<br><br>\n",
    "Я считаю, что NDCG более бизнесовая метрика, то есть показывает результат который больше связан с задачами бизнеса, а именно что лучше порекомендовать. В таком случае нам выгоднее использовать гибридный рекомендатор, но я думаю, что такой результат был очевиден заранее, так как понято, что контентные признаки несут в себе полезную информацию и дадут нашей модели больше точек опоры и следовательно большую точность. Также не стоит забывать что конекретная CF модель как раз старалась минимизировать RMSE, за счёт чего и имеет лучший показатель по ней, но RMSE не свосем честная метрика, так как рейтинг это порядковая величина(то есть 5-4 != 2-1), а использая RMSE мы как будто забываем про это.<br>\n",
    "\n",
    "\n",
    "\n",
    "<!-- Хоть моя попытка сделать контентную модель провалилась, в техническом плане, всё равно можно сказать, что контентные признаки несут в себе полезную информацию и точность у такой модели должна быть выше, чем у чисто коллоборативной.<br><br>\n",
    "Также в будущем можно улучшить точность обеих моделей в выбранных метриках, если заставить модели оптимизировать именно эти метрики, но целесообразность этого стоит проверить на A/B тестах. Не всегда хорошие значения в метрике, значит что рекомендательная система хорошо работает, онлайн метрики в совокупности с офлайн дают более полной представлнение о качестве работы системы.\n",
    "<br><br> -->\n",
    "\n",
    "<!-- P.S.:<br>\n",
    "Я потратил слишком много времени и сил на кросс валидацию и копание в моделях, чем на выполнение самого задание.<br> Сейчас очевидо, что подбирать и брать большие гиперпараметры это не такая значимая часть исследования.<br> Лучшее несколько теоритических моделей, чем одна кроссвалидированая)<br>\n",
    "Попробую переделать контентную модель, но уже в не рамках зачёта.<br>\n",
    " -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 165.844,
   "position": {
    "height": "206.844px",
    "left": "17px",
    "right": "20px",
    "top": "88px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
